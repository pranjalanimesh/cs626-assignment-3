{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"eriktks/conll2003\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Mapping of NER tags as per CoNLL-2003\n",
    "# These tags are typically:\n",
    "# 0: O\n",
    "# 1: B-PER\n",
    "# 2: I-PER\n",
    "# 3: B-ORG\n",
    "# 4: I-ORG\n",
    "# 5: B-LOC\n",
    "# 6: I-LOC\n",
    "# 7: B-MISC\n",
    "# 8: I-MISC\n",
    "ner_tag_map = {\n",
    "    0: 'O',\n",
    "    1: 'B-PER',\n",
    "    2: 'I-PER',\n",
    "    3: 'B-ORG',\n",
    "    4: 'I-ORG',\n",
    "    5: 'B-LOC',\n",
    "    6: 'I-LOC',\n",
    "    7: 'B-MISC',\n",
    "    8: 'I-MISC'\n",
    "}\n",
    "\n",
    "# Function to map numerical NER tags to BIO labels\n",
    "def map_ner_tags(dataset_split):\n",
    "    for example in dataset_split:\n",
    "        example['ner_tags'] = [ner_tag_map[tag] for tag in example['ner_tags']]\n",
    "    return dataset_split\n",
    "\n",
    "# Apply mapping to all splits\n",
    "dataset['train'] = map_ner_tags(dataset['train'])\n",
    "dataset['validation'] = map_ner_tags(dataset['validation'])\n",
    "dataset['test'] = map_ner_tags(dataset['test'])\n",
    "\n",
    "# Function to extract features from a token\n",
    "def extract_features(tokens, pos_tags, chunk_tags, idx):\n",
    "    token = tokens[idx]\n",
    "    pos = pos_tags[idx]\n",
    "    chunk = chunk_tags[idx]\n",
    "    \n",
    "    features = {\n",
    "        'token': token,\n",
    "        'pos': pos,\n",
    "        'chunk': chunk,\n",
    "    }\n",
    "    \n",
    "    # Previous token features\n",
    "    if idx > 0:\n",
    "        features['prev_token'] = tokens[idx - 1]\n",
    "        features['prev_pos'] = pos_tags[idx - 1]\n",
    "    else:\n",
    "        features['prev_token'] = 'BOS'  # Beginning of sentence\n",
    "        features['prev_pos'] = 'BOS'\n",
    "        \n",
    "    # Next token features\n",
    "    if idx < len(tokens) - 1:\n",
    "        features['next_token'] = tokens[idx + 1]\n",
    "        features['next_pos'] = pos_tags[idx + 1]\n",
    "    else:\n",
    "        features['next_token'] = 'EOS'  # End of sentence\n",
    "        features['next_pos'] = 'EOS'\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Prepare the dataset for training\n",
    "def prepare_data(dataset_split):\n",
    "    X = []\n",
    "    y = []\n",
    "    for example in dataset_split:\n",
    "        tokens = example['tokens']\n",
    "        pos_tags = example['pos_tags']\n",
    "        chunk_tags = example['chunk_tags']\n",
    "        ner_tags = example['ner_tags']\n",
    "        for idx in range(len(tokens)):\n",
    "            X.append(extract_features(tokens, pos_tags, chunk_tags, idx))\n",
    "            y.append(ner_tags[idx])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM classifier...\n",
      "Training completed.\n",
      "Predicting on the validation set...\n",
      "Evaluation on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     42759\n",
      "           1       0.97      0.73      0.83      1842\n",
      "           2       0.96      0.80      0.88      1307\n",
      "           3       0.90      0.73      0.81      1341\n",
      "           4       0.90      0.70      0.79       751\n",
      "           5       0.93      0.81      0.87      1837\n",
      "           6       0.91      0.79      0.84       257\n",
      "           7       0.93      0.80      0.86       922\n",
      "           8       0.88      0.66      0.75       346\n",
      "\n",
      "    accuracy                           0.96     51362\n",
      "   macro avg       0.93      0.78      0.85     51362\n",
      "weighted avg       0.96      0.96      0.96     51362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare training data\n",
    "X_train, y_train = prepare_data(dataset['train'])\n",
    "X_val, y_val = prepare_data(dataset['validation'])\n",
    "X_test, y_test = prepare_data(dataset['test'])\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Vectorize the features\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "# Using a linear kernel for efficiency; you can experiment with other kernels\n",
    "classifier = svm.LinearSVC()\n",
    "\n",
    "# Train the classifier\n",
    "print(\"Training the SVM classifier...\")\n",
    "classifier.fit(X_train_vectorized, y_train_encoded)\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Predict on the validation set\n",
    "print(\"Predicting on the validation set...\")\n",
    "y_val_pred = classifier.predict(X_val_vectorized)\n",
    "\n",
    "# Decode the labels\n",
    "y_val_pred_labels = label_encoder.inverse_transform(y_val_pred)\n",
    "y_val_true_labels = label_encoder.inverse_transform(y_val_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluation on Validation Set:\")\n",
    "print(classification_report(y_val_true_labels, y_val_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on the test set...\n",
      "Evaluation on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     38323\n",
      "           1       0.95      0.57      0.71      1617\n",
      "           2       0.94      0.69      0.79      1156\n",
      "           3       0.85      0.63      0.72      1661\n",
      "           4       0.84      0.64      0.73       835\n",
      "           5       0.89      0.76      0.82      1668\n",
      "           6       0.80      0.67      0.73       257\n",
      "           7       0.83      0.72      0.77       702\n",
      "           8       0.68      0.64      0.66       216\n",
      "\n",
      "    accuracy                           0.94     46435\n",
      "   macro avg       0.86      0.70      0.77     46435\n",
      "weighted avg       0.93      0.94      0.93     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "print(\"Predicting on the test set...\")\n",
    "y_test_pred = classifier.predict(X_test_vectorized)\n",
    "y_test_pred_labels = label_encoder.inverse_transform(y_test_pred)\n",
    "y_test_true_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluation on Test Set:\")\n",
    "print(classification_report(y_test_true_labels, y_test_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
      "Output: SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
      "\n",
      "Input: Nadim Ladki\n",
      "Output: Nadim Ladki\n",
      "\n",
      "Input: AL-AIN , United Arab Emirates 1996-12-06\n",
      "Output: AL-AIN , United_B Arab_I Emirates_I 1996-12-06\n",
      "\n",
      "Input: Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday .\n",
      "Output: Japan_B began the defence of their Asian_B Cup_I title with a lucky 2-1 win against Syria_B in a Group C championship match on Friday .\n",
      "\n",
      "Input: But China saw their luck desert them in the second match of the group , crashing to a surprise 2-0 defeat to newcomers Uzbekistan .\n",
      "Output: But China_B saw their luck desert them in the second match of the group , crashing to a surprise 2-0 defeat to newcomers Uzbekistan .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Corrected format_output function\n",
    "def format_output(dataset_split, predictions):\n",
    "    formatted_sentences = []\n",
    "    current_index = 0  # Pointer to track the position in predictions\n",
    "    \n",
    "    for example in dataset_split:\n",
    "        tokens = example['tokens']\n",
    "        num_tokens = len(tokens)\n",
    "\n",
    "        # Extract the predictions for the current sentence\n",
    "        pred = predictions[current_index:current_index + num_tokens]\n",
    "        current_index += num_tokens  # Move the pointer forward\n",
    "        \n",
    "        tagged_tokens = []\n",
    "        for token, p in zip(tokens, pred):\n",
    "            tag = ner_tag_map[p]\n",
    "            if tag == 'O':\n",
    "                tagged_tokens.append(token)\n",
    "            else:\n",
    "                # Split the tag into BIO and entity type\n",
    "                try:\n",
    "                    bio, entity = tag.split('-')\n",
    "                    tagged_tokens.append(f\"{token}_{bio}\")\n",
    "                except ValueError:\n",
    "                    # Handle cases where the tag might not follow the expected format\n",
    "                    tagged_tokens.append(token)\n",
    "        \n",
    "        formatted_sentence = ' '.join(tagged_tokens)\n",
    "        formatted_sentences.append(formatted_sentence)\n",
    "    \n",
    "    return formatted_sentences\n",
    "\n",
    "# Format the test set predictions using the corrected function\n",
    "formatted_test_output = format_output(dataset['test'], y_test_pred_labels)\n",
    "\n",
    "# Display some examples\n",
    "for i in range(5):\n",
    "    print(f\"Input: {' '.join(dataset['test'][i]['tokens'])}\")\n",
    "    print(f\"Output: {formatted_test_output[i]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
